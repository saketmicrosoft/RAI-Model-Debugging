{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%configure -f\r\n",
        "{\r\n",
        "    \"name\": \"synapseml\",\r\n",
        "    \"conf\": {\r\n",
        "        \"spark.jars.packages\": \"com.microsoft.azure:synapseml_2.12:0.9.5\",\r\n",
        "        \"spark.jars.excludes\": \"org.scala-lang:scala-reflect,org.apache.spark:spark-tags_2.12,org.scalactic:scalactic_2.12,org.scalatest:scalatest_2.12,com.azure:azure-core\",\r\n",
        "        \"spark.yarn.user.classpath.first\": \"true\"\r\n",
        "    }\r\n",
        "}"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "session_starting",
              "livy_statement_state": null,
              "queued_time": "2022-02-02T22:21:22.2548168Z",
              "session_start_time": "2022-02-02T22:21:22.3022912Z",
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , SessionStarting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\r\n",
        "from pyspark.ml.classification import GBTClassifier\r\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\r\n",
        "import pyspark.sql.functions as F\r\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\r\n",
        "\r\n",
        "from synapse.ml.explainers import ICETransformer\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "waiting",
              "livy_statement_state": null,
              "queued_time": "2022-02-02T22:21:22.3409247Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , Waiting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.sql(\"SELECT * FROM RAIDEMO\")\r\n",
        "display(df)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "waiting",
              "livy_statement_state": null,
              "queued_time": "2022-02-02T22:21:22.6862184Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , Waiting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.select('WarehouseID','ItemID','TotalYTDSales','CurrentInventory',\r\n",
        "        'AmountToOrder', 'AverageWeekWastage', 'IsPerishable', 'HasFlatSellingRate', 'IsSeasonSensitive', \r\n",
        "        'MonthNumber','WeekNumberMonth','WeekNumberYear', 'TotalMembersInCurrentCity','AverageOnlineOrdAmtInPastWeeks')"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "waiting",
              "livy_statement_state": null,
              "queued_time": "2022-02-02T22:21:23.5051435Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , Waiting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features = ['WarehouseID','ItemID', 'IsPerishable', 'HasFlatSellingRate', 'IsSeasonSensitive', \r\n",
        "        'MonthNumber','WeekNumberMonth','WeekNumberYear']\r\n",
        "numeric_features = ['TotalYTDSales','CurrentInventory','AverageWeekWastage', 'TotalMembersInCurrentCity','AverageOnlineOrdAmtInPastWeeks']"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "waiting",
              "livy_statement_state": null,
              "queued_time": "2022-02-02T22:21:24.0206809Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , Waiting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from synapse.ml.exploratory import AggregateBalanceMeasure, DistributionBalanceMeasure, FeatureBalanceMeasure\r\n",
        "import pyspark.sql.functions as F\r\n",
        "from pyspark.sql.types import StringType,IntegerType,BooleanType\r\n",
        "\r\n",
        "df.withColumn(\"IsPerishable\",df.IsPerishable.cast(StringType()))\r\n",
        "\r\n",
        "cols = [\"HasFlatSellingRate\", \"IsSeasonSensitive\", \"IsPerishable\"]\r\n",
        "for col2 in cols:\r\n",
        "    df = df.withColumn(\r\n",
        "        col2, \r\n",
        "        F.when(\r\n",
        "            F.col(col2) == 'True',\r\n",
        "            '1'\r\n",
        "        ).when(\r\n",
        "            F.col(col2) == 'False',\r\n",
        "            '0'\r\n",
        "        ).otherwise(F.col(col2).cast('string'))\r\n",
        "    )\r\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "waiting",
              "livy_statement_state": null,
              "queued_time": "2022-02-02T22:21:24.5364159Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , Waiting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from synapse.ml.exploratory import AggregateBalanceMeasure, DistributionBalanceMeasure, FeatureBalanceMeasure\r\n",
        "import pyspark.sql.functions as F\r\n",
        "from pyspark.sql.types import StringType,IntegerType,BooleanType\r\n",
        "\r\n",
        "df.withColumn(\"AmountToOrder\", df.AmountToOrder.cast(IntegerType()))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "waiting",
              "livy_statement_state": null,
              "queued_time": "2022-02-02T22:21:24.9385049Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , Waiting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn(\"AmountToOrder\", F.when(F.col(\"AmountToOrder\") < 6600, F.lit(0)).otherwise(F.lit(1))).drop('id')\r\n",
        "df.head(10)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "waiting",
              "livy_statement_state": null,
              "queued_time": "2022-02-02T22:21:25.3352734Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , Waiting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "string_indexer_outputs = [feature + \"_idx\" for feature in categorical_features]\r\n",
        "one_hot_encoder_outputs = [feature + \"_enc\" for feature in categorical_features]\r\n",
        "\r\n",
        "pipeline = Pipeline(stages=[\r\n",
        "    StringIndexer().setInputCol('AmountToOrder').setOutputCol(\"label\"), #.setStringOrderType(\"alphabetAsc\")\r\n",
        "    StringIndexer().setInputCols(categorical_features).setOutputCols(string_indexer_outputs),\r\n",
        "    OneHotEncoder().setInputCols(string_indexer_outputs).setOutputCols(one_hot_encoder_outputs),\r\n",
        "    VectorAssembler(inputCols=one_hot_encoder_outputs+numeric_features, outputCol=\"features\"),\r\n",
        "    GBTClassifier( maxDepth=7, maxIter=10)]) #weightCol=\"fnlwgt\",\r\n",
        "\r\n",
        "model = pipeline.fit(df)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "waiting",
              "livy_statement_state": null,
              "queued_time": "2022-02-02T22:21:25.7387622Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , Waiting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = model.transform(df)\r\n",
        "display(data.select('AmountToOrder', 'probability', 'prediction'))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "waiting",
              "livy_statement_state": null,
              "queued_time": "2022-02-02T22:21:27.0900756Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , Waiting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_auc = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"prediction\")\r\n",
        "eval_auc.evaluate(data)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "waiting",
              "livy_statement_state": null,
              "queued_time": "2022-02-02T22:21:27.6060607Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , Waiting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdp = ICETransformer(model=model, targetCol=\"probability\", kind=\"average\", targetClasses=[1],\r\n",
        "                     categoricalFeatures=categorical_features, numericFeatures=numeric_features, numSamples = 500000)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "waiting",
              "livy_statement_state": null,
              "queued_time": "2022-02-02T22:21:28.2163105Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , Waiting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Disable BroadcastHashJoin, so Spark will use standard SortMergeJoin. Currently, Hyperspace indexes utilize SortMergeJoin to speed up query.\r\n",
        "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)\r\n",
        "\r\n",
        "# Verify that BroadcastHashJoin is set correctly \r\n",
        "print(spark.conf.get(\"spark.sql.autoBroadcastJoinThreshold\"))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "waiting",
              "livy_statement_state": null,
              "queued_time": "2022-02-02T22:21:28.6253272Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , Waiting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_pdp = pdp.transform(df)\r\n",
        "display(output_pdp)\r\n",
        "output_pdp.cache()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "waiting",
              "livy_statement_state": null,
              "queued_time": "2022-02-02T22:21:29.0433454Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , Waiting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions for visualization\r\n",
        "\r\n",
        "def get_pandas_df_from_column(df, col_name):\r\n",
        "  keys_df = df.select(F.explode(F.map_keys(F.col(col_name)))).distinct()\r\n",
        "  keys = list(map(lambda row: row[0], keys_df.collect()))\r\n",
        "  key_cols = list(map(lambda f: F.col(col_name).getItem(f).alias(str(f)), keys))\r\n",
        "  final_cols = key_cols\r\n",
        "  pandas_df = df.select(final_cols).toPandas()\r\n",
        "  return pandas_df\r\n",
        "\r\n",
        "def plot_dependence_for_categorical(df, col, col_int=True, figsize=(20, 5)):\r\n",
        "  dict_values = {}\r\n",
        "  col_names = list(df.columns)\r\n",
        "\r\n",
        "  for col_name in col_names:\r\n",
        "    dict_values[col_name] = df[col_name][0].toArray()[0]\r\n",
        "    marklist= sorted(dict_values.items(), key=lambda x: int(x[0]) if col_int else x[0]) \r\n",
        "    sortdict=dict(marklist)\r\n",
        "\r\n",
        "  fig = plt.figure(figsize = figsize)\r\n",
        "  plt.bar(sortdict.keys(), sortdict.values())\r\n",
        "\r\n",
        "  plt.xlabel(col, size=13)\r\n",
        "  plt.ylabel(\"Dependence\")\r\n",
        "  plt.show()\r\n",
        "  \r\n",
        "def plot_dependence_for_numeric(df, col, col_int=True, figsize=(20, 5)):\r\n",
        "  dict_values = {}\r\n",
        "  col_names = list(df.columns)\r\n",
        "\r\n",
        "  for col_name in col_names:\r\n",
        "    dict_values[col_name] = df[col_name][0].toArray()[0]\r\n",
        "    marklist= sorted(dict_values.items(), key=lambda x: int(x[0]) if col_int else x[0]) \r\n",
        "    sortdict=dict(marklist)\r\n",
        "\r\n",
        "  fig = plt.figure(figsize = figsize)\r\n",
        "\r\n",
        "  \r\n",
        "  plt.plot(list(sortdict.keys()), list(sortdict.values()))\r\n",
        "\r\n",
        "  plt.xlabel(col, size=13)\r\n",
        "  plt.ylabel(\"Dependence\")\r\n",
        "  plt.ylim(0.0)\r\n",
        "  plt.show()\r\n",
        "  "
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "waiting",
              "livy_statement_state": null,
              "queued_time": "2022-02-02T22:21:29.5468067Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , Waiting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_education_num = get_pandas_df_from_column(output_pdp, 'WarehouseID_dependence')\r\n",
        "plot_dependence_for_numeric(df_education_num, 'WarehouseID')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}